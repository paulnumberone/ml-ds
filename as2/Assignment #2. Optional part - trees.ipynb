{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\" />\n",
    "    \n",
    "## [mlcourse.ai](https://mlcourse.ai) – Open Machine Learning Course \n",
    "Author: [Yury Kashnitsky](https://yorko.github.io) (@yorko). Edited by Anna Tarelina (@feuerengel). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Assignment #2. Optional part\n",
    "## <center> Implementation of the decision tree algorithm\n",
    "    \n",
    "#  <center>  <font color = 'red'> Warning! </font>This is a very useful but ungraded assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets import make_classification, make_regression, load_digits, load_boston\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix `random_state` (a.k.a. random seed) beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Implement the class `DecisionTree`**\n",
    "**Specification:**\n",
    "- the class is inherited from `sklearn.BaseEstimator`;\n",
    "- class constructor has the following parameters: \n",
    "    `max_depth` - maximum depth of the tree (`numpy.inf` by default); \n",
    "    `min_samples_split` - the minimum number of instances in a node for a splitting to be done (2 by default); \n",
    "    `criterion` - split criterion ('gini' or 'entropy' for classification, 'variance' or 'mad_median' for regression; 'gini' by default);\n",
    "    \n",
    "    A functional to be maximized to find an optimal partition at a given node has the form\n",
    "    $$Q(X, j, t) = F(X) - \\dfrac{|X_l|}{|X|} F(X_l) - \\dfrac{|X_r|}{|X|} F(X_r),$$\n",
    "    where $X$ are samples at a given node, $X_l$ and $X_r$ are partitions of samples $X$ into two parts \n",
    "    with the following condition $[x_j < t]$, and $F(X)$ is a partition criterion.\n",
    "    \n",
    "    For classification: let $p_i$ be the fraction of the instances of the $i$-th class in the dataset $X$.\n",
    "    \n",
    "    'gini': Gini impurity $F(X) = 1 -\\sum_{i = 1}^K p_i^2$.\n",
    "    \n",
    "    'entropy': Entropy $F(X) = -\\sum_{i = 1}^K p_i \\log_2(p_i)$.\n",
    "    \n",
    "    For regression: $y_j = y(x_j)$ - is a target for an instance $x_j$, $y = (y_1, \\dots, y_{|X|})$ - is a target vector.\n",
    "    \n",
    "    'variance': Variance (mean quadratic deviation from average) $F(X) = \\dfrac{1}{|X|} \\sum_{x_j \\in X}(y_j - \\dfrac{1}{|X|}\\sum_{x_i \\in X}y_i)^2$\n",
    "    \n",
    "    'mad_median': Mean deviation from the median $F(X) = \\dfrac{1}{|X|} \\sum_{x_j \\in X}|y_j - \\mathrm{med}(y)|$\n",
    "    \n",
    "- the class has several methods: `fit`, `predict` and `predict_proba`;\n",
    "- the`fit` method takes the matrix of instances `X` and a target vector `y` (`numpy.ndarray` objects) and returns an instance of the class `DecisionTree` representing the decision tree trained on the dataset `(X, y)` according to parameters set in the constructor; \n",
    "- the `predict_proba` method takes the matrix of instances `X` and returns the matrix `P` of a size `X.shape[0] x K`, where `K` is the number of classes and $p_{ij}$ is the probability of an instance in $i$-th row of `X` to belong to class $j \\in \\{1, \\dots, K\\}$.\n",
    "- the `predict` method takes the matrix of instances `X` and returns a prediction vector; in case of classification, prediction for an instance $x_i$ falling into leaf $L$ will be the class, mostly represented among instances in $L$. In case of regression, it'll be the mean value of targets for all instances in leaf $L$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):    \n",
    "    pass\n",
    "\n",
    "def gini(y):\n",
    "    pass\n",
    "\n",
    "def variance(y):\n",
    "    pass\n",
    "\n",
    "def mad_median(y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Node` class implements a node in the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    \n",
    "    def __init__(self, feature_idx=0, threshold=0, labels=None, left=None, right=None):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.threshold = threshold\n",
    "        self.labels = labels\n",
    "        self.left = left\n",
    "        self.right = right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's determine the function for calculating a prediction in a leaf. For regression, let's take the mean for all values in a leaf, for classification - the most popular class in leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, max_depth=np.inf, min_samples_split=2, \n",
    "                 criterion='gini', debug=False):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "        \n",
    "    def predict(self, X):\n",
    "        pass\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the implemented algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset `digits` using the method `load_digits`. Split the data into train and test with the `train_test_split` method, use parameter values `test_size=0.2`, and `random_state=17`. Try to train shallow decision trees and make sure that gini and entropy criteria return different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    ">>> from sklearn.datasets import load_digits\n",
    ">>> digits = load_digits()\n",
    ">>> print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = train_test_split(digits.data, digits.target, test_size=0.3,\n",
    "random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion='entropy')\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8425925925925926"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tree_pred = tree.predict(X_holdout)\n",
    "accuracy_score(y_holdout, tree_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 5-folds cross-validation (`GridSearchCV`) pick up the optimal values of the `max_depth` and `criterion` parameters. For the parameter `max_depth` use range(3, 11), for criterion use {'gini', 'entropy'}. Quality measure is `scoring`='accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 9}\n",
      "0.86793953858393\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tree_params = {'max_depth': range(3, 11), 'criterion': ['gini', 'entropy']}\n",
    "tree_grid = GridSearchCV(tree, tree_params, cv=5, n_jobs=-1)\n",
    "tree_grid.fit(X_train, y_train)\n",
    "print(tree_grid.best_params_)\n",
    "print(tree_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the plot of the mean quality measure `accuracy` for criteria `gini` and `entropy` depending on `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#не нашел как"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Choose all correct statements:**\n",
    "1. Optimal value of the `max_depth` parameter is on the interval [4, 9] for both criteria.\n",
    "2. Created plots have no intersection on the interval [3, 10]\n",
    "3. Created plots intersect each other only once on the interval [3, 10].\n",
    "4. The best quality for `max_depth` on the interval [3, 10] is reached using `gini` criterion .\n",
    "5. Accuracy is strictly increasing at least for one of the criteria, when `max_depth` is also increasing on the interval [3, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. What are the optimal values for max_depth and criterion parameters?**\n",
    "1. max_depth = 7, criterion = 'gini';\n",
    "2. max_depth = 7, criterion = 'entropy';\n",
    "3. max_depth = 10, criterion = 'entropy';\n",
    "4. max_depth = 10, criterion = 'gini';\n",
    "5. max_depth = 9, criterion = 'entropy';\n",
    "6. max_depth = 9, criterion = 'gini';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train decision tree on `(X_train, y_train)` using the optimal values of `max_depth` and `criterion`. Compute class probabilities for `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8481481481481481"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth = 10, criterion='entropy')\n",
    "tree.fit(X_train, y_train)\n",
    "tree_pred = tree.predict(X_holdout)\n",
    "accuracy_score(y_holdout, tree_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the given matrix, compute the mean class probabilities for all instances in `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([49., 54., 52., 46., 56., 58., 50., 63., 49., 63.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(tree_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1167"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(tree_pred.shape[0]):\n",
    "    if tree_pred[i] == 9:\n",
    "        cnt +=1\n",
    "round(cnt/tree_pred.shape[0], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. What is the maximum probability in a resulted vector?**\n",
    "1. 0.127\n",
    "2. 0.118\n",
    "3. 1.0\n",
    "4. 0.09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset `boston` using the method `load_boston`. Split the data into train and test with the `train_test_split` method, use parameter values `test_size=0.2`, `random_state=17`. Try to train shallow regression decision trees and make sure that `variance` and `mad_median` criteria return different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    }
   ],
   "source": [
    ">>> from sklearn.datasets import load_boston\n",
    ">>> boston = load_boston()\n",
    ">>> print(boston.data.shape)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(boston.data, boston.target, test_size=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 5-folds cross-validation (`GridSearchCV`) pick up the optimal values of the `max_depth` and `criterion` parameters. For the parameter `max_depth` use `range(2, 9)`, for `criterion` use {'variance', 'mad_median'}. Quality measure is `scoring`='neg_mean_squared_error'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_depth': range(2, 9), 'criterion': ['mse', 'friedman_mse']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree2 = DecisionTreeRegressor()\n",
    "tree_params2 = {'max_depth': range(2, 9), 'criterion': ['mse', 'friedman_mse']} #'variance', 'mad_median' не пашут\n",
    "tree_grid2 = GridSearchCV(tree2, tree_params2, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "\n",
    "tree_grid2.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the plot of the mean quality measure `neg_mean_squared_error` for criteria `variance` and `mad_median` depending on `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'friedman_mse', 'max_depth': 5}\n",
      "-21.000950087568725\n"
     ]
    }
   ],
   "source": [
    "print(tree_grid2.best_params_)\n",
    "print(tree_grid2.best_score_)\n",
    "#не нашел как"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Choose all correct statements:**\n",
    "1. Created plots have no intersection on the interval [2, 8].\n",
    "2. Created plots intersect each other only once on the interval [2, 8].\n",
    "3. Optimal value of the `max_depth` for each of the criteria is on the border of the interval [2, 8].\n",
    "4. The best quality at `max_depth` on the interval [2, 8] is reached using `mad_median` criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. What are the optimal values for `max_depth` and `criterion` parameters?**\n",
    "1. max_depth = 9, criterion = 'variance';\n",
    "2. max_depth = 5, criterion = 'mad_median';\n",
    "3. max_depth = 4, criterion = 'variance';\n",
    "4. max_depth = 2, criterion = 'mad_median';\n",
    "5. max_depth = 4, criterion = 'mad_median';\n",
    "6. max_depth = 5, criterion = 'variance'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "lesson4_part2_Decision_trees.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
